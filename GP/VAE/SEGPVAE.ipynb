{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22ca6353-974f-4ddc-aae9-a02ef50bdd02",
   "metadata": {},
   "source": [
    "### Notebook for training the SEGPVAE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "071b1128-1259-44ee-b593-3cd83b23e823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "root = '/qfs/projects/atscale/atscale_dyn/'\n",
    "sys.path.append(root + 'Code/atscale/GP/SEGP')\n",
    "import TrainVAE_Tools as TVAE\n",
    "import VAE as VAE\n",
    "import SEGP as SEGP\n",
    "import ModifyShape as ModShap\n",
    "import ELBO as ELBO\n",
    "\n",
    "import GP_Tools as GPT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cc535f5-dd5e-471f-abf6-928eb040d43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default tensor type is now cuda\n",
      "Device in use is:  cuda\n",
      "mean_0 complete!\n",
      "mean_1 complete!\n",
      "K_00 complete!\n",
      "K_01 complete!\n",
      "K_11 complete!\n",
      "A =  tensor([[-1., -0., -0., -0.],\n",
      "        [-0., -1., -0., -0.],\n",
      "        [-0., -0., -1., -0.],\n",
      "        [-0., -0., -0., -1.]])\n",
      "B =  tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]])\n",
      "C =  Parameter containing:\n",
      "tensor([[ 1.3201, -0.3840, -0.1967, -0.0208],\n",
      "        [ 1.3048, -0.4893,  0.2697, -1.9343]], requires_grad=True)\n",
      "D =  tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Posterior computed!\n",
      "Posterior sampled!\n",
      "recon =  tensor(56872.5175, grad_fn=<DivBackward0>)\n",
      "GCE =  tensor(1348.9943, grad_fn=<AddBackward0>)\n",
      "lml =  tensor(-412.5122, grad_fn=<SubBackward0>)\n",
      "loss =  tensor(-57808.9996, grad_fn=<NegBackward0>)\n",
      "loss computed!\n",
      "mean_0 complete!\n",
      "mean_1 complete!\n",
      "K_00 complete!\n",
      "K_01 complete!\n",
      "K_11 complete!\n",
      "A =  tensor([[-1., -0., -0., -0.],\n",
      "        [-0., -1., -0., -0.],\n",
      "        [-0., -0., -1., -0.],\n",
      "        [-0., -0., -0., -1.]])\n",
      "B =  tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]])\n",
      "C =  Parameter containing:\n",
      "tensor([[ 1.3211, -0.3850, -0.1977, -0.0198],\n",
      "        [ 1.3038, -0.4883,  0.2707, -1.9353]], requires_grad=True)\n",
      "D =  tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Posterior computed!\n",
      "Posterior sampled!\n",
      "recon =  tensor(59609.9530, grad_fn=<DivBackward0>)\n",
      "GCE =  tensor(1657.5382, grad_fn=<AddBackward0>)\n",
      "lml =  tensor(-401.0449, grad_fn=<SubBackward0>)\n",
      "loss =  tensor(-60866.4462, grad_fn=<NegBackward0>)\n",
      "loss computed!\n",
      "mean_0 complete!\n",
      "mean_1 complete!\n",
      "K_00 complete!\n",
      "K_01 complete!\n",
      "K_11 complete!\n",
      "A =  tensor([[-1., -0., -0., -0.],\n",
      "        [-0., -1., -0., -0.],\n",
      "        [-0., -0., -1., -0.],\n",
      "        [-0., -0., -0., -1.]])\n",
      "B =  tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]])\n",
      "C =  Parameter containing:\n",
      "tensor([[ 1.3220, -0.3859, -0.1984, -0.0190],\n",
      "        [ 1.3029, -0.4874,  0.2715, -1.9361]], requires_grad=True)\n",
      "D =  tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Posterior computed!\n",
      "Posterior sampled!\n",
      "recon =  tensor(64088.1627, grad_fn=<DivBackward0>)\n",
      "GCE =  tensor(2195.6829, grad_fn=<AddBackward0>)\n",
      "lml =  tensor(-362.5208, grad_fn=<SubBackward0>)\n",
      "loss =  tensor(-65921.3248, grad_fn=<NegBackward0>)\n",
      "loss computed!\n",
      "mean_0 complete!\n",
      "mean_1 complete!\n",
      "K_00 complete!\n",
      "K_01 complete!\n",
      "K_11 complete!\n",
      "A =  tensor([[-1., -0., -0., -0.],\n",
      "        [-0., -1., -0., -0.],\n",
      "        [-0., -0., -1., -0.],\n",
      "        [-0., -0., -0., -1.]])\n",
      "B =  tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]])\n",
      "C =  Parameter containing:\n",
      "tensor([[ 1.3230, -0.3868, -0.1992, -0.0182],\n",
      "        [ 1.3020, -0.4865,  0.2723, -1.9370]], requires_grad=True)\n",
      "D =  tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Posterior computed!\n",
      "Posterior sampled!\n",
      "recon =  tensor(72584.5716, grad_fn=<DivBackward0>)\n",
      "GCE =  tensor(3299.4511, grad_fn=<AddBackward0>)\n",
      "lml =  tensor(-353.6232, grad_fn=<SubBackward0>)\n",
      "loss =  tensor(-75530.3994, grad_fn=<NegBackward0>)\n",
      "loss computed!\n",
      "mean_0 complete!\n",
      "mean_1 complete!\n",
      "K_00 complete!\n",
      "K_01 complete!\n",
      "K_11 complete!\n",
      "A =  tensor([[-1., -0., -0., -0.],\n",
      "        [-0., -1., -0., -0.],\n",
      "        [-0., -0., -1., -0.],\n",
      "        [-0., -0., -0., -1.]])\n",
      "B =  tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]])\n",
      "C =  Parameter containing:\n",
      "tensor([[ 1.3238, -0.3876, -0.2001, -0.0174],\n",
      "        [ 1.3012, -0.4856,  0.2732, -1.9379]], requires_grad=True)\n",
      "D =  tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Posterior computed!\n",
      "Posterior sampled!\n",
      "recon =  tensor(85459.8576, grad_fn=<DivBackward0>)\n",
      "GCE =  tensor(5118.8735, grad_fn=<AddBackward0>)\n",
      "lml =  tensor(-302.8272, grad_fn=<SubBackward0>)\n",
      "loss =  tensor(-90275.9040, grad_fn=<NegBackward0>)\n",
      "loss computed!\n",
      "mean_0 complete!\n",
      "mean_1 complete!\n",
      "K_00 complete!\n",
      "K_01 complete!\n",
      "K_11 complete!\n",
      "A =  tensor([[-1., -0., -0., -0.],\n",
      "        [-0., -1., -0., -0.],\n",
      "        [-0., -0., -1., -0.],\n",
      "        [-0., -0., -0., -1.]])\n",
      "B =  tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]])\n",
      "C =  Parameter containing:\n",
      "tensor([[ 1.3247, -0.3885, -0.2010, -0.0165],\n",
      "        [ 1.3003, -0.4848,  0.2740, -1.9388]], requires_grad=True)\n",
      "D =  tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Posterior computed!\n",
      "Posterior sampled!\n",
      "recon =  tensor(102346.0352, grad_fn=<DivBackward0>)\n",
      "GCE =  tensor(8831.0025, grad_fn=<AddBackward0>)\n",
      "lml =  tensor(-377.8024, grad_fn=<SubBackward0>)\n",
      "loss =  tensor(-110799.2353, grad_fn=<NegBackward0>)\n",
      "loss computed!\n",
      "mean_0 complete!\n",
      "mean_1 complete!\n",
      "K_00 complete!\n",
      "K_01 complete!\n",
      "K_11 complete!\n",
      "A =  tensor([[-1., -0., -0., -0.],\n",
      "        [-0., -1., -0., -0.],\n",
      "        [-0., -0., -1., -0.],\n",
      "        [-0., -0., -0., -1.]])\n",
      "B =  tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]])\n",
      "C =  Parameter containing:\n",
      "tensor([[ 1.3255, -0.3894, -0.2013, -0.0157],\n",
      "        [ 1.2994, -0.4839,  0.2749, -1.9398]], requires_grad=True)\n",
      "D =  tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Posterior computed!\n",
      "Posterior sampled!\n",
      "recon =  tensor(125470.0265, grad_fn=<DivBackward0>)\n",
      "GCE =  tensor(16389.3011, grad_fn=<AddBackward0>)\n",
      "lml =  tensor(inf, grad_fn=<SubBackward0>)\n",
      "loss =  tensor(-inf, grad_fn=<NegBackward0>)\n",
      "loss computed!\n",
      "mean_0 complete!\n",
      "mean_1 complete!\n",
      "K_00 complete!\n",
      "K_01 complete!\n",
      "K_11 complete!\n",
      "A =  tensor([[-1., -0., -0., -0.],\n",
      "        [-0., -1., -0., -0.],\n",
      "        [-0., -0., -1., -0.],\n",
      "        [-0., -0., -0., -1.]])\n",
      "B =  tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]])\n",
      "C =  Parameter containing:\n",
      "tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]], requires_grad=True)\n",
      "D =  tensor([[0., 0.],\n",
      "        [0., 0.]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "torch.linalg.eig: input tensor should not contain infs or NaNs.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 98\u001b[0m\n\u001b[1;32m     95\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(model_params, f)\n\u001b[1;32m     96\u001b[0m     f\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m---> 98\u001b[0m model, stats \u001b[38;5;241m=\u001b[39m \u001b[43mTVAE\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmax_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecay_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/qfs/projects/atscale/atscale_dyn/Code/atscale/GP/VAE/TrainVAE_Tools.py:147\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_loader, test_loader, MS, T, enc, GP, dec, optimizer, criterion, max_epoch, model_dir, decay, decay_epochs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC = \u001b[39m\u001b[38;5;124m'\u001b[39m, GP\u001b[38;5;241m.\u001b[39mC)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD = \u001b[39m\u001b[38;5;124m'\u001b[39m, GP\u001b[38;5;241m.\u001b[39mD)\n\u001b[0;32m--> 147\u001b[0m \u001b[43mGPT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_K\u001b[49m\u001b[43m(\u001b[49m\u001b[43mK_prior\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m mu_post, K_post \u001b[38;5;241m=\u001b[39m GP\u001b[38;5;241m.\u001b[39mposterior( MS\u001b[38;5;241m.\u001b[39mprior_2_lml(mu_prior, K_prior), \n\u001b[1;32m    150\u001b[0m                                MS\u001b[38;5;241m.\u001b[39menc_2_lml(mu_lhood, var_lhood) ) \u001b[38;5;66;03m# (bs*m*tmax) & (bs*m*tmax, bs*m*tmax)\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPosterior computed!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/qfs/projects/atscale/atscale_dyn/Code/atscale/GP/SEGP/GP_Tools.py:475\u001b[0m, in \u001b[0;36mtest_K\u001b[0;34m(K_mat, tol_sym, tol_pos)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03mTests if K_mat is symmetric and positive definite.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;124;03margs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;124;03m    True if both conditions are met.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    474\u001b[0m dimK \u001b[38;5;241m=\u001b[39m K_mat\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 475\u001b[0m eigs_K \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meigvals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mK_mat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    477\u001b[0m sym_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mallclose( K_mat, K_mat\u001b[38;5;241m.\u001b[39mt(), atol\u001b[38;5;241m=\u001b[39mtol_sym )\n\u001b[1;32m    478\u001b[0m eig_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mall( torch\u001b[38;5;241m.\u001b[39mge( torch\u001b[38;5;241m.\u001b[39mreal(eigs_K), \u001b[38;5;241m-\u001b[39mtol_pos\u001b[38;5;241m*\u001b[39mtorch\u001b[38;5;241m.\u001b[39mones(dimK) ) )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: torch.linalg.eig: input tensor should not contain infs or NaNs."
     ]
    }
   ],
   "source": [
    "# main\n",
    "\n",
    "# user settings - data\n",
    "N = 1 # dataset number to load\n",
    "data_path = root + 'Data/GP/Data/Dataset{0}/'.format(N)\n",
    "bs = 10\n",
    "n_batch = 100\n",
    "test_split = 0. # 0.2 # ratio of batches reserved for testing\n",
    "\n",
    "# user settings - model\n",
    "exp_no = 1 # experiment number\n",
    "model_name = 'SEGPVAE/'\n",
    "model_dir = root + 'Data/GP/Models/' + model_name + 'Exp_{:03d}/'.format(exp_no)\n",
    "\n",
    "# B = None\n",
    "C = None\n",
    "# D = None\n",
    "B = torch.tensor([[0, 0],\n",
    "                  [0, 0],\n",
    "                  [1, 0],\n",
    "                  [0, 1]\n",
    "                 ], dtype=torch.double)\n",
    "        \n",
    "# C = torch.tensor([[1, 0, 0, 0], \n",
    "#                   [0, 1, 0, 0]], dtype=torch.double)\n",
    "\n",
    "D = torch.zeros((2,2), dtype=torch.double)\n",
    "\n",
    "# user settings - training\n",
    "max_epoch = 1\n",
    "lr = 1e-2 # learning rate\n",
    "wd = 1e-5 # weight decay\n",
    "decay = 0.1 # scalar to multiply lr by at decay_epochs\n",
    "decay_epochs = [75, 90] # epochs to perform lr cut\n",
    "\n",
    "###################################################################################################\n",
    "\n",
    "# Hardware agnostic settings\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device.type == 'cuda':\n",
    "    print('Default tensor type is now cuda')\n",
    "    torch.set_default_dtype(torch.float64)\n",
    "    \n",
    "print(\"Device in use is: \", device)\n",
    "\n",
    "\n",
    "if os.path.isdir(model_dir):\n",
    "    raise Exception(\"File already exists! Do not overwrite\")\n",
    "else:\n",
    "    os.makedirs(model_dir)\n",
    "    os.makedirs(model_dir + '/Encoder')\n",
    "    os.makedirs(model_dir + '/GP')\n",
    "    os.makedirs(model_dir + '/Decoder')\n",
    "\n",
    "\n",
    "train_loader, test_loader, T, mean_U, mean_U_dt, exp_setup = TVAE.getData(data_path, test_split, bs, n_batch)\n",
    "\n",
    "if model_name == 'SEGPVAE/':\n",
    "    m = exp_setup['m'] # dimension of output\n",
    "    n = exp_setup['n'] # dimension of state\n",
    "    p = exp_setup['p'] # dimension of input\n",
    "    lt = exp_setup['lt'] # length scale used for SE kernel of the input\n",
    "    time = exp_setup['time'] # initial time, final time and integration step\n",
    "    mean_x0 = torch.from_numpy( exp_setup['mean_x0'] ).to(dtype=torch.double)\n",
    "    cov_x0 = torch.from_numpy( exp_setup['cov_x0'] ).to(dtype=torch.double)\n",
    "    cov_eta = torch.from_numpy( exp_setup['cov_eta'] ).to(dtype=torch.double)\n",
    "    tmax = len(T)\n",
    "    py = exp_setup['py']\n",
    "    px = exp_setup['px']\n",
    "    h_dim = 500\n",
    "\n",
    "    enc = VAE.VAEEncoder(py*px, h_dim, m)\n",
    "    GP = SEGP.SEGP(m, n, p, lt, time, mean_x0, mean_U, mean_U_dt, cov_x0, cov_eta, tmax, B, C, D)\n",
    "    dec = VAE.VAEDecoder(m, h_dim, py*px)\n",
    "\n",
    "MS = ModShap.Modify_Shape(bs, m) # class for modifying shape of tensors.\n",
    "criterion = ELBO.ELBO(bs, m) # We want to maximise this!\n",
    "optimizer = torch.optim.Adam(list(enc.parameters()) + list(GP.parameters()) + list(dec.parameters()),\n",
    "                             lr=lr, weight_decay=wd)\n",
    "\n",
    "# log experiment settings\n",
    "run_settings = {'N':N, 'bs':bs, 'n_batch':n_batch, 'test_split':test_split, \\\n",
    "               'exp_no':exp_no, 'model_name':model_name, 'model_dir':model_dir, \\\n",
    "                'max_epoch':max_epoch, 'lr':lr, 'wd':wd, 'decay':decay, \\\n",
    "                'decay_epochs':decay_epochs, 'device':device}\n",
    "\n",
    "model_params = {'m':m, 'n':n, 'p':p, 'lt':lt, 'time':time, 'mean_x0':mean_x0, 'cov_x0':cov_x0, \\\n",
    "                'cov_eta':cov_eta, 'tmax':tmax, 'B':B, 'C':C, 'D':D, 'py':py, 'px':px, 'h_dim':h_dim}\n",
    "\n",
    "\n",
    "with open(model_dir+'run_settings.pkl', 'wb') as f:\n",
    "    pickle.dump(run_settings, f)\n",
    "    f.close()\n",
    "with open(model_dir+'model_params.pkl', 'wb') as f:\n",
    "    pickle.dump(model_params, f)\n",
    "    f.close()\n",
    "\n",
    "model, stats = TVAE.train(train_loader, test_loader, MS, T, enc, GP, dec, optimizer, criterion, \n",
    "                          max_epoch, model_dir, decay, decay_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e59e78-57f2-47b7-a276-3cc68eb405c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bounds = []\n",
    "TVAE.plot_loss(model_dir, 'training', stats, max_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50113360-245e-4d0a-bc59-d80dfe64ae6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
